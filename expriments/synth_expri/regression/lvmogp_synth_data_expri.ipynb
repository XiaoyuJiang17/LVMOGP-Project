{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from linear_operator.operators import KroneckerProductLinearOperator\n",
    "from torch import Tensor\n",
    "from torch.distributions import MultivariateNormal\n",
    "from lvmogp_svi import LVMOGP_SVI\n",
    "from gaussian_likelihood import GaussianLikelihood\n",
    "from variational_elbo import VariationalELBO\n",
    "from tqdm import trange\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from util_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Without missing data \n",
    "#### Note we keep any C_index-like variable referring to indices in total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expri_random_seed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in synthetic data (only call this function once)\n",
    "wo_n_C_total = 700 # totally 700 points for C\n",
    "wo_n_outputs = 20\n",
    "wo_X_true, wo_C_total, wo_sample_total_data, kernel_parameters = tidily_sythetic_data_from_MOGP(n_C=wo_n_C_total, n_X=wo_n_outputs, random_seed=expri_random_seed)\n",
    "# sample_total_data: of length n_outputs * n_C_total.\n",
    "\n",
    "wo_n_C_train = 20\n",
    "wo_n_C_test = wo_n_C_total - wo_n_C_train\n",
    "\n",
    "random.seed(expri_random_seed)\n",
    "wo_train_C_tidily_indices = random.sample(range(wo_n_C_total), wo_n_C_train) # of length n_C_train\n",
    "wo_test_C_tidily_indices = [index for index in range(wo_n_C_total) if index not in wo_train_C_tidily_indices] # of length n_C_test\n",
    "\n",
    "# list (n_outputs) of list (n_C_train), \n",
    "wo_ls_of_ls_train_C = [wo_train_C_tidily_indices for _ in range(wo_n_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_sample_train_index = wo_train_C_tidily_indices\n",
    "for i in range(1,wo_n_outputs): # 20 outputs, except the first one is already included\n",
    "    wo_sample_train_index = np.concatenate((wo_sample_train_index, list(np.array(wo_train_C_tidily_indices) + wo_n_C_total*i)))\n",
    "\n",
    "wo_sample_test_index = wo_test_C_tidily_indices\n",
    "for i in range(1,wo_n_outputs): # 20 outputs, except the first one is already included\n",
    "    wo_sample_test_index = np.concatenate((wo_sample_test_index, list(np.array(wo_test_C_tidily_indices) + wo_n_C_total*i)))\n",
    "\n",
    "assert wo_sample_train_index.shape[0] == wo_n_C_train * wo_n_outputs\n",
    "assert wo_sample_test_index.shape[0] == wo_n_C_test* wo_n_outputs\n",
    "assert np.isin(wo_sample_train_index, wo_sample_test_index).sum() == 0\n",
    "\n",
    "wo_sample_train_data = wo_sample_total_data[wo_sample_train_index]\n",
    "wo_sample_test_data = wo_sample_total_data[wo_sample_test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Variables here are: ls_of_ls_train_C, sample_train_index, sample_test_index, sample_train_data, sample_test_data, sample_total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variational_strategy.inducing_points_X torch.Size([30, 2])\n",
      "variational_strategy.inducing_points_C torch.Size([15, 1])\n",
      "variational_strategy._variational_distribution.variational_mean torch.Size([450])\n",
      "variational_strategy._variational_distribution.chol_variational_covar_X torch.Size([30, 30])\n",
      "variational_strategy._variational_distribution.chol_variational_covar_C torch.Size([15, 15])\n",
      "X.q_mu torch.Size([20, 2])\n",
      "X.q_log_sigma torch.Size([20, 2])\n",
      "covar_module_X.raw_outputscale torch.Size([])\n",
      "covar_module_X.base_kernel.raw_lengthscale torch.Size([1, 2])\n",
      "covar_module_C.raw_outputscale torch.Size([])\n",
      "covar_module_C.base_kernel.raw_lengthscale torch.Size([1, 1])\n",
      "---------------------------------------------\n",
      "noise_covar.raw_noise torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#  define hyper-parameters\n",
    "train_style = 'all-together' # 'all-together' or 'em-style'\n",
    "train_parameters =  'all-parameters' #'fix-kernel-parameters' or 'all-parameters'\n",
    "wo_n_X_model = wo_n_outputs\n",
    "wo_n_C_model = wo_n_C_train\n",
    "wo_n_total_model = wo_n_X_model * wo_n_C_model\n",
    "wo_index_dim = 1\n",
    "wo_latent_dim = 2\n",
    "wo_n_inducing_C = 15\n",
    "wo_n_inducing_X = 30\n",
    "wo_pca = False\n",
    "\n",
    "# specify model\n",
    "wo_my_model = LVMOGP_SVI(wo_n_X_model, wo_n_C_model, wo_index_dim, wo_latent_dim, wo_n_inducing_C, wo_n_inducing_X, wo_sample_train_data.reshape(wo_n_X_model, -1), pca=wo_pca)\n",
    "\n",
    "# Likelihood & training objective\n",
    "wo_likelihood = GaussianLikelihood()\n",
    "wo_mll = VariationalELBO(wo_likelihood, wo_my_model, num_data=wo_n_total_model)\n",
    "\n",
    "# have a look at parameters\n",
    "for name, param in wo_my_model.named_parameters():\n",
    "    print(name, param.size())\n",
    "\n",
    "print('---' * 15) \n",
    "for name, param in wo_likelihood.named_parameters():\n",
    "    print(name, param.size())\n",
    "\n",
    "# Initialize inducing points in C space\n",
    "wo_my_model.variational_strategy.inducing_points_C.data = torch.rand(wo_n_inducing_C).reshape(-1,1) * 20 - 10\n",
    "# This depends on interval (-10,10) appear in tidily_sythetic_data_from_MOGP\n",
    "\n",
    "# following parameters are initialized as ground truth values ... and fixed!\n",
    "if train_parameters == 'fix-kernel-parameters':\n",
    "    wo_my_model.covar_module_X.raw_outputscale.data = kernel_parameters['X_raw_outputscale']\n",
    "    wo_my_model.covar_module_X.raw_outputscale.requires_grad = False\n",
    "    wo_my_model.covar_module_X.base_kernel.raw_lengthscale.data = kernel_parameters['X_raw_lengthscale']\n",
    "    wo_my_model.covar_module_X.base_kernel.raw_lengthscale.requires_grad = False\n",
    "    wo_my_model.covar_module_C.raw_outputscale.data = kernel_parameters['C_raw_outputscale']\n",
    "    wo_my_model.covar_module_C.raw_outputscale.requires_grad = False\n",
    "    wo_my_model.covar_module_C.base_kernel.raw_lengthscale.data = kernel_parameters['C_raw_lengthscale']\n",
    "    wo_my_model.covar_module_C.base_kernel.raw_lengthscale.requires_grad = False\n",
    "\n",
    "    # optimizer and scheduler\n",
    "    if train_style == 'all-together':\n",
    "        model_params_to_optimize = [\n",
    "            param for name, param in wo_my_model.named_parameters()\n",
    "            if not name.startswith('covar_module_X') and not name.startswith('covar_module_C')\n",
    "        ]\n",
    "\n",
    "        wo_optimizer = torch.optim.Adam([\n",
    "        {'params': model_params_to_optimize},\n",
    "        {'params': wo_likelihood.parameters()} # likelihood parameter is fixed or not.\n",
    "        ], lr=0.3)\n",
    "\n",
    "        wo_scheduler = StepLR(wo_optimizer, step_size=50, gamma=0.95)  # 0.3, 50, 0.95; \n",
    "\n",
    "    elif train_style == 'em-style':\n",
    "\n",
    "        variational_params = [\n",
    "            param for name, param in wo_my_model.named_parameters()\n",
    "            if name.startswith('variational_strategy')\n",
    "        ]\n",
    "\n",
    "        x_params = [\n",
    "            param for name, param in wo_my_model.named_parameters()\n",
    "            if name.startswith('X')\n",
    "        ]\n",
    "\n",
    "        wo_optimizer_e_step = torch.optim.Adam(variational_params, lr=0.3)\n",
    "        wo_scheduler_e_step = StepLR(wo_optimizer_e_step, step_size=50, gamma=0.95)\n",
    "\n",
    "        wo_optimizer_m_step = torch.optim.Adam([{'params': x_params}, {'params': wo_likelihood.parameters()}], lr=0.3)\n",
    "        wo_scheduler_m_step = StepLR(wo_optimizer_m_step, step_size=50, gamma=0.95)\n",
    "\n",
    "elif train_parameters == 'all-parameters':\n",
    "    \n",
    "    # optimizer and scheduler\n",
    "    if train_style == 'all-together':\n",
    "        \n",
    "        wo_optimizer = torch.optim.Adam([\n",
    "        {'params': wo_my_model.parameters()},\n",
    "        {'params': wo_likelihood.parameters()} # likelihood parameter is fixed or not.\n",
    "        ], lr=0.3)\n",
    "\n",
    "        wo_scheduler = StepLR(wo_optimizer, step_size=50, gamma=0.95)  # 0.3, 50, 0.95; \n",
    "        \n",
    "    elif train_style == 'em-style':\n",
    "\n",
    "        variational_params = [\n",
    "            param for name, param in wo_my_model.named_parameters()\n",
    "            if name.startswith('variational_strategy')\n",
    "        ]\n",
    "\n",
    "        covar_and_x_params = [\n",
    "            param for name, param in wo_my_model.named_parameters()\n",
    "            if name.startswith('covar_module') or name.startswith('X')\n",
    "        ]\n",
    "\n",
    "        wo_optimizer_e_step = torch.optim.Adam(variational_params, lr=0.3)\n",
    "        wo_scheduler_e_step = StepLR(wo_optimizer_e_step, step_size=50, gamma=0.95)\n",
    "        \n",
    "        wo_optimizer_m_step = torch.optim.Adam([{'params': covar_and_x_params}, {'params': wo_likelihood.parameters()}], lr=0.3)\n",
    "        wo_scheduler_m_step = StepLR(wo_optimizer_m_step, step_size=50, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.635, iter no: 1499: 100%|██████████| 1500/1500 [03:12<00:00,  7.81it/s]\n"
     ]
    }
   ],
   "source": [
    "if train_style == 'all-together':\n",
    "    # start training!\n",
    "    wo_loss_list = []\n",
    "    n_iterations = 1500 # 10000\n",
    "    iterator = trange(n_iterations, leave=True)\n",
    "    batch_size_X = 20\n",
    "    batch_size_C = wo_n_C_train # how many training inputs\n",
    "    wo_model_max_grad_norm = 15\n",
    "    wo_likeli_max_grad_norm = 0.7\n",
    "\n",
    "    wo_my_model.train()\n",
    "    wo_likelihood.train()\n",
    "    for i in iterator: \n",
    "        # The following step ensures samples C are all 'valid' training ones.\n",
    "        batch_index_X, batch_index_C = sample_index_X_and_C_from_list(wo_ls_of_ls_train_C, batch_size_X, batch_size_C)\n",
    "        # core code is here \n",
    "        wo_optimizer.zero_grad()\n",
    "        # sample_batch_X = wo_my_model.sample_latent_variable(batch_idx=None)\n",
    "        sample_X = wo_my_model.sample_latent_variable()  # a full sample returns latent x across all n_X, not scalable when n_X is large TODO: more efficient?\n",
    "        sample_batch_X = sample_X[batch_index_X]\n",
    "        sample_batch_C = wo_C_total[batch_index_C]\n",
    "        output_batch = wo_my_model(sample_batch_X, sample_batch_C) # q(f)\n",
    "        batch_index_Y = inhomogeneous_index_of_batch_Y(batch_index_X, batch_index_C, wo_n_X_model, wo_n_C_total) # n_C_total is because all c index considered are based on C_total.\n",
    "        loss = -wo_mll(output_batch, wo_sample_total_data[batch_index_Y]).sum()\n",
    "        wo_loss_list.append(loss.item())\n",
    "        iterator.set_description('Loss: ' + str(float(np.round(loss.item(),3))) + \", iter no: \" + str(i))\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(wo_my_model.parameters(), wo_model_max_grad_norm)\n",
    "        torch.nn.utils.clip_grad_norm_(wo_likelihood.parameters(), wo_likeli_max_grad_norm)\n",
    "\n",
    "        wo_optimizer.step()\n",
    "        wo_scheduler.step()\n",
    "\n",
    "elif train_style == 'em-style':\n",
    "    \n",
    "    # start training!\n",
    "    wo_loss_list = []\n",
    "    n_iterations = 3000 # 10000\n",
    "    iterator = trange(n_iterations, leave=True)\n",
    "    batch_size_X = 20\n",
    "    batch_size_C = 50\n",
    "    wo_model_max_grad_norm = 15\n",
    "    wo_likeli_max_grad_norm = 0.7\n",
    "\n",
    "    wo_my_model.train()\n",
    "    wo_likelihood.train()\n",
    "    iteration_tracker = 0\n",
    "    for i in iterator: \n",
    "        # The following step ensures samples C are all 'valid' training ones.\n",
    "        batch_index_X, batch_index_C = sample_index_X_and_C_from_list(wo_ls_of_ls_train_C, batch_size_X, batch_size_C)\n",
    "        # core code is here \n",
    "        wo_optimizer_e_step.zero_grad()\n",
    "        wo_optimizer_m_step.zero_grad()\n",
    "        sample_X = wo_my_model.sample_latent_variable()  # a full sample returns latent x across all n_X TODO: more efficient?\n",
    "        sample_batch_X = sample_X[batch_index_X]\n",
    "        sample_batch_C = wo_C_total[batch_index_C]\n",
    "        output_batch = wo_my_model(sample_batch_X, sample_batch_C) # q(f)\n",
    "        batch_index_Y = inhomogeneous_index_of_batch_Y(batch_index_X, batch_index_C, wo_n_X_model, wo_n_C_total) # n_C_total is because all c index considered are based on C_total.\n",
    "        loss = -wo_mll(output_batch, wo_sample_total_data[batch_index_Y]).sum()\n",
    "        wo_loss_list.append(loss.item())\n",
    "        iterator.set_description('Loss: ' + str(float(np.round(loss.item(),3))) + \", iter no: \" + str(i))\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(wo_my_model.parameters(), wo_model_max_grad_norm)\n",
    "        torch.nn.utils.clip_grad_norm_(wo_likelihood.parameters(), wo_likeli_max_grad_norm)\n",
    "\n",
    "        \n",
    "        if iteration_tracker <= 60: \n",
    "            wo_optimizer_e_step.step()\n",
    "            wo_scheduler_e_step.step()\n",
    "            iteration_tracker += 1\n",
    "\n",
    "        elif iteration_tracker > 60 and iteration_tracker <= 100:\n",
    "            wo_optimizer_m_step.step()\n",
    "            wo_scheduler_m_step.step()\n",
    "\n",
    "            if iteration_tracker != 100:\n",
    "                iteration_tracker += 1\n",
    "            else:\n",
    "                iteration_tracker = 0\n",
    "        '''\n",
    "        if i % 3 == 1 or i % 3 == 2:\n",
    "            wo_optimizer_e_step.step()\n",
    "            wo_scheduler_e_step.step()\n",
    "        else:\n",
    "            wo_optimizer_m_step.step()\n",
    "            wo_scheduler_m_step.step()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdce7558280>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(wo_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After Training, have a look at fitted kernel parameters...\\n')\n",
    "\n",
    "print('model covar_module_X raw output_scale\\n', wo_my_model.covar_module_X.raw_outputscale.data)\n",
    "print('model covar_module_X base kernel raw lengthscale\\n', wo_my_model.covar_module_X.base_kernel.raw_lengthscale.data)\n",
    "print('model covar_module_C raw outputscale\\n', wo_my_model.covar_module_C.raw_outputscale.data)\n",
    "print('model covar_module_C base_kernel raw lengthscale\\n', wo_my_model.covar_module_C.base_kernel.raw_lengthscale.data)\n",
    "print('likelihood noise_covar raw noise', wo_likelihood.noise_covar.raw_noise.data)\n",
    "\n",
    "print('----- ----- ' * 10)\n",
    "\n",
    "print('model covar_module_X output_scale\\n', wo_my_model.covar_module_X.outputscale.data)\n",
    "print('model covar_module_X base kernel lengthscale\\n', wo_my_model.covar_module_X.base_kernel.lengthscale.data)\n",
    "print('model covar_module_C outputscale\\n', wo_my_model.covar_module_C.outputscale.data)\n",
    "print('model covar_module_C base_kernel lengthscale\\n', wo_my_model.covar_module_C.base_kernel.lengthscale.data)\n",
    "print('likelihood noise_covar noise', wo_likelihood.noise_covar.noise.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction output for all grid (total) inputs.\n",
    "wo_my_model.eval()\n",
    "wo_likelihood.eval()\n",
    "\n",
    "batch_size_X = wo_n_outputs\n",
    "batch_size_C = wo_n_C_total # this number must equal to n_total = 700 !\n",
    "sample_X = wo_my_model.X.q_mu.data # TODO: try other meaningful approaches\n",
    "\n",
    "# indices for all inputs.\n",
    "batch_index_X = np.array([[i]*batch_size_C for i in range(batch_size_X)]).reshape(-1).tolist() \n",
    "batch_index_C = [i for i in range(batch_size_C)] * batch_size_X \n",
    "\n",
    "assert len(batch_index_X) == len(batch_index_C)\n",
    "\n",
    "sample_batch_X = sample_X[batch_index_X]\n",
    "sample_batch_C = wo_C_total[batch_index_C]\n",
    "# NOTE: predictions for ALL inputs. \n",
    "wo_grid_output_batch = wo_my_model(sample_batch_X, sample_batch_C) # q(f)\n",
    "# passing through likelihood.\n",
    "wo_grid_output_batch = wo_likelihood(wo_grid_output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# prediction output for all grid (total) inputs.\n",
    "wo_my_model.eval()\n",
    "wo_likelihood.eval()\n",
    "\n",
    "batch_size_X = wo_n_outputs\n",
    "batch_size_C = wo_n_C_total # this number must equal to n_total = 700!\n",
    "mean_tensor = wo_my_model.X.q_mu.data \n",
    "log_sigma_tensor = wo_my_model.X.q_log_sigma.data\n",
    "sample_X_tensor = sample_from_multivariantgaussian(mean_tensor, log_sigma_tensor, monte_carlo_samples=3)\n",
    "\n",
    "# indices for all inputs.\n",
    "batch_index_X = np.array([[i]*batch_size_C for i in range(batch_size_X)]).reshape(-1).tolist() \n",
    "batch_index_C = [i for i in range(batch_size_C)] * batch_size_X \n",
    "\n",
    "assert len(batch_index_X) == len(batch_index_C)\n",
    "\n",
    "_, wo_grid_output_batch = mc_pred_helper(wo_my_model, wo_likelihood, sample_X_tensor, wo_C_total, batch_index_X, batch_index_C)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test RMSE (Global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_train_data_predict = wo_grid_output_batch.loc.detach()[wo_sample_train_index]\n",
    "train_rmse = (wo_train_data_predict - wo_sample_train_data).square().mean().sqrt()\n",
    "print('Global Train RMSE', train_rmse)\n",
    "\n",
    "wo_test_data_predict = wo_grid_output_batch.loc.detach()[wo_sample_test_index]\n",
    "test_rmse = (wo_test_data_predict - wo_sample_test_data).square().mean().sqrt()\n",
    "print('Global Test RMSE', test_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the index of the funtion to show\n",
    "wo_function_index = 17 # 0 - 19 (in total 20 output functions)\n",
    "\n",
    "# Train\n",
    "wo_train_input = wo_C_total[wo_train_C_tidily_indices]\n",
    "wo_train_start = wo_train_input.shape[0] * wo_function_index\n",
    "wo_train_end = wo_train_start + wo_train_input.shape[0]\n",
    "wo_train_target = wo_sample_train_data[wo_train_start:wo_train_end]\n",
    "\n",
    "wo_train_pred_mean = wo_train_data_predict[wo_train_start:wo_train_end]\n",
    "wo_train_pred_std = wo_grid_output_batch.stddev.detach()[wo_sample_train_index][wo_train_start:wo_train_end]\n",
    "print('Train RMSE', (wo_train_pred_mean - wo_train_target).square().mean().sqrt())\n",
    "\n",
    "\n",
    "# Test\n",
    "wo_test_input = wo_C_total[wo_test_C_tidily_indices]\n",
    "wo_test_start = wo_test_input.shape[0] * wo_function_index\n",
    "wo_test_end = wo_test_start + wo_test_input.shape[0]\n",
    "wo_test_target = wo_sample_test_data[wo_test_start:wo_test_end]\n",
    "\n",
    "wo_test_pred_mean = wo_test_data_predict[wo_test_start:wo_test_end]\n",
    "wo_test_pred_std = wo_grid_output_batch.stddev.detach()[wo_sample_test_index][wo_test_start:wo_test_end]\n",
    "print('Test RMSE', (wo_test_pred_mean - wo_test_target).square().mean().sqrt())\n",
    "\n",
    "# Total\n",
    "wo_gp_input = wo_C_total\n",
    "wo_gp_start = wo_gp_input.shape[0] * wo_function_index\n",
    "wo_gp_end = wo_gp_start + wo_gp_input.shape[0]\n",
    "wo_gp_target = wo_sample_total_data[wo_gp_start:wo_gp_end]\n",
    "\n",
    "wo_gp_pred_mean = wo_grid_output_batch.loc.detach()[wo_gp_start:wo_gp_end]\n",
    "wo_gp_pred_std = wo_grid_output_batch.stddev.detach()[wo_gp_start:wo_gp_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traindata_testdata_fittedgp(train_X=wo_train_input, train_Y=wo_train_target, test_X=wo_test_input, test_Y=wo_test_target, gp_X=wo_gp_input, gp_pred_mean=wo_gp_pred_mean, gp_pred_std=wo_gp_pred_std, inducing_points_X=wo_my_model.variational_strategy.inducing_points_C.detach(), n_inducing_C=wo_n_inducing_C) # NOTE: input is C not X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True v.s. Fitted latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_and_fitted_latent(wo_X_true, wo_my_model.X.q_mu.detach(), torch.nn.functional.softplus(wo_my_model.X.q_log_sigma.detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expri_random_seed = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is same as 'no missing data' case.\n",
    "w_n_C_total = 700 # totally 700 points for C\n",
    "w_n_outputs = 20\n",
    "w_X_true, w_C_total, w_sample_total_data, kernel_parameters = tidily_sythetic_data_from_MOGP(n_C=w_n_C_total, n_X=w_n_outputs)\n",
    "\n",
    "w_n_C_train = 20 # the number of training data points per output\n",
    "w_n_C_test = w_n_C_total - w_n_C_train\n",
    "\n",
    "np.random.seed(expri_random_seed)\n",
    "list_expri_random_seeds = np.random.randn(w_n_outputs)\n",
    "print(list_expri_random_seeds)\n",
    "\n",
    "# different from the previous case, C_train and C_test no longer a single set, but every output has different values.\n",
    "w_ls_of_ls_train_C = []\n",
    "w_ls_of_ls_test_C = []\n",
    "\n",
    "w_sample_train_index, w_sample_test_index = [], []\n",
    "\n",
    "for i in range(w_n_outputs):\n",
    "    # iterate across different output functions\n",
    "    random.seed(list_expri_random_seeds[i])\n",
    "    train_index = random.sample(range(w_n_C_total), w_n_C_train)\n",
    "    test_index = [index for index in range(w_n_C_total) if index not in train_index]\n",
    "    w_ls_of_ls_train_C.append(train_index)\n",
    "    w_ls_of_ls_test_C.append(test_index)\n",
    "    '''\n",
    "    C_train = C_total[train_index]\n",
    "    C_test = C_total[test_index]\n",
    "    assert C_train.shape[0] == n_train\n",
    "    assert C_test.shape[0] == n_test\n",
    "    C_train_List.append(C_train)\n",
    "    C_test_List.append(C_test)\n",
    "    '''\n",
    "    w_sample_train_index = np.concatenate((w_sample_train_index, list(np.array(train_index) + w_n_C_total*i)))\n",
    "    w_sample_test_index = np.concatenate((w_sample_test_index, list(np.array(test_index) + w_n_C_total*i)))\n",
    "\n",
    "w_sample_train_data = w_sample_total_data[w_sample_train_index]\n",
    "w_sample_test_data = w_sample_total_data[w_sample_test_index]\n",
    "\n",
    "assert w_sample_train_data.shape[0] == w_n_C_train * w_n_outputs\n",
    "assert w_sample_test_data.shape[0] == w_n_C_test * w_n_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_functions import sample_index_X_and_C_from_list\n",
    "# define hyper-parameters\n",
    "w_n_X = w_X_true.shape[0]\n",
    "w_n_C = len(w_ls_of_ls_train_C[0])\n",
    "w_n_total = w_n_X * w_n_C\n",
    "w_index_dim = 1\n",
    "w_latent_dim = 2\n",
    "w_n_inducing_C = 15\n",
    "w_n_inducing_X = 30\n",
    "w_pca = False\n",
    "\n",
    "Y_train = w_sample_train_data\n",
    "\n",
    "# specify model\n",
    "w_my_model = LVMOGP_SVI(w_n_X, w_n_C, w_index_dim, w_latent_dim, w_n_inducing_C, w_n_inducing_X, Y_train.reshape(w_n_X, -1), pca=w_pca)\n",
    "\n",
    "# Likelihood & training objective\n",
    "w_likelihood = GaussianLikelihood()\n",
    "w_mll = VariationalELBO(w_likelihood, w_my_model, num_data=w_n_total)\n",
    "\n",
    "# load in partially-trained model\n",
    "load_model = False\n",
    "load_likelihood = False\n",
    "if load_model:\n",
    "    model_path = '/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/models/model_weights.pth'\n",
    "    state_dict = torch.load(model_path)\n",
    "    w_my_model.load_state_dict(state_dict)\n",
    "\n",
    "if load_likelihood:\n",
    "    likelihood_path = '/Users/jiangxiaoyu/Desktop/All Projects/GPLVM_project_code/models/likelihood_weights.pth'\n",
    "    state_dict = torch.load(likelihood_path)\n",
    "    w_likelihood.load_state_dict(state_dict)\n",
    "\n",
    "# optimizer and scheduler\n",
    "w_optimizer = torch.optim.Adam([\n",
    "    {'params': w_my_model.parameters()},\n",
    "    {'params': w_likelihood.parameters()} \n",
    "], lr=0.3)\n",
    "\n",
    "w_scheduler = StepLR(w_optimizer, step_size=50, gamma=0.95)  # every 50 iterations，learning rate multiple 0.95\n",
    "\n",
    "# have a look at parameters\n",
    "for name, param in w_my_model.named_parameters():\n",
    "    print(name, param.size())\n",
    "\n",
    "print('---' * 15) \n",
    "for name, param in w_likelihood.named_parameters():\n",
    "    print(name, param.size())\n",
    "\n",
    "# Initialize inducing points in C space\n",
    "w_my_model.variational_strategy.inducing_points_C.data = torch.rand(wo_n_inducing_C).reshape(-1,1) * 20 - 10\n",
    "# This depends on interval (-10,10) appear in tidily_sythetic_data_from_MOGP\n",
    "\n",
    "# start training!\n",
    "w_loss_list = []\n",
    "n_iterations = 1500 # 10000\n",
    "iterator = trange(n_iterations, leave=True)\n",
    "batch_size_X = 20\n",
    "batch_size_C = w_n_C_train # 50\n",
    "w_model_max_grad_norm = 15\n",
    "w_likeli_max_grad_norm = 0.7\n",
    "\n",
    "w_my_model.train()\n",
    "w_likelihood.train()\n",
    "for i in iterator: \n",
    "    batch_index_X, batch_index_C = sample_index_X_and_C_from_list(w_ls_of_ls_train_C, batch_size_X=batch_size_X, batch_size_C=batch_size_C)\n",
    "    # core code is here \n",
    "    w_optimizer.zero_grad()\n",
    "    sample_X = w_my_model.sample_latent_variable()  # a full sample returns latent x across all n_X TODO: more efficient?\n",
    "    sample_batch_X = sample_X[batch_index_X]\n",
    "    sample_batch_C = w_C_total[batch_index_C]\n",
    "    output_batch = w_my_model(sample_batch_X, sample_batch_C) # q(f)\n",
    "    batch_index_Y = inhomogeneous_index_of_batch_Y(batch_index_X, batch_index_C, w_n_X, w_n_C_total)\n",
    "    loss = -w_mll(output_batch, w_sample_total_data[batch_index_Y]).sum()\n",
    "    w_loss_list.append(loss.item())\n",
    "    iterator.set_description('Loss: ' + str(float(np.round(loss.item(),3))) + \", iter no: \" + str(i))\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients\n",
    "    torch.nn.utils.clip_grad_norm_(w_my_model.parameters(), w_model_max_grad_norm)\n",
    "    torch.nn.utils.clip_grad_norm_(w_likelihood.parameters(), w_likeli_max_grad_norm)\n",
    "\n",
    "    w_optimizer.step()\n",
    "    w_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(w_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction output for grid (total) inputs.\n",
    "w_my_model.eval()\n",
    "w_likelihood.eval()\n",
    "\n",
    "batch_size_X = 20\n",
    "batch_size_C = 700 # this number must equal to n_total = 700 !\n",
    "sample_X = w_my_model.X.q_mu # TODO: try other meaningful approaches, such as monte carlo samling approximation ...\n",
    "\n",
    "batch_index_X = np.array([[i]*batch_size_C for i in range(batch_size_X)]).reshape(-1).tolist() \n",
    "batch_index_C = [i for i in range(batch_size_C)] * batch_size_X \n",
    "\n",
    "assert len(batch_index_X) == len(batch_index_C)\n",
    "\n",
    "sample_batch_X = sample_X[batch_index_X]\n",
    "sample_batch_C = w_C_total[batch_index_C]\n",
    "w_grid_output_batch = w_my_model(sample_batch_X, sample_batch_C) # q(f)\n",
    "# passing through likelihood\n",
    "w_grid_output_batch = w_likelihood(w_grid_output_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test data RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train_data_predict = w_grid_output_batch.loc.detach()[w_sample_train_index]\n",
    "train_rmse = (w_train_data_predict - w_sample_train_data).square().mean().sqrt()\n",
    "print('Train RMSE', train_rmse)\n",
    "\n",
    "w_test_data_predict = w_grid_output_batch.loc.detach()[w_sample_test_index]\n",
    "test_rmse = (w_test_data_predict - w_sample_test_data).square().mean().sqrt()\n",
    "print('Test RMSE', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the index of the funtion to show\n",
    "w_function_index = 13 # 0 - 19 (in total 20 output functions)\n",
    "\n",
    "w_train_input = w_C_total[w_ls_of_ls_train_C[w_function_index]]\n",
    "w_train_start = 0\n",
    "for i in range(w_function_index):\n",
    "    w_train_start += len(w_ls_of_ls_train_C[i]) # don't assume every output has the same length of inputs\n",
    "w_train_end = w_train_start + len(w_ls_of_ls_train_C[w_function_index])\n",
    "w_train_target = w_sample_train_data[w_train_start:w_train_end]\n",
    "w_train_predict = w_train_data_predict[w_train_start:w_train_end]\n",
    "train_rmse = (w_train_target - w_train_predict).square().mean().sqrt()\n",
    "print('train rmse', train_rmse)\n",
    "\n",
    "w_test_input = w_C_total[w_ls_of_ls_test_C[w_function_index]]\n",
    "w_test_start = 0\n",
    "for j in range(w_function_index):\n",
    "    w_test_start += len(w_ls_of_ls_test_C[i])\n",
    "w_test_end = w_test_start + len(w_ls_of_ls_test_C[w_function_index])\n",
    "w_test_target = w_sample_test_data[w_test_start:w_test_end]\n",
    "w_test_predict = w_test_data_predict[w_test_start:w_test_end]\n",
    "test_rmse = (w_test_predict - w_test_target).square().mean().sqrt()\n",
    "print('test rmse', test_rmse)\n",
    "\n",
    "w_gp_input = w_C_total\n",
    "w_gp_start = w_gp_input.shape[0] * w_function_index\n",
    "w_gp_end = w_gp_start + w_gp_input.shape[0]\n",
    "w_gp_target = w_sample_total_data[w_gp_start:w_gp_end]\n",
    "\n",
    "\n",
    "w_gp_pred_mean = w_grid_output_batch.loc.detach()[w_gp_start:w_gp_end]\n",
    "w_gp_pred_std = w_grid_output_batch.stddev.detach()[w_gp_start:w_gp_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traindata_testdata_fittedgp(train_X=w_train_input, train_Y=w_train_target, test_X=w_test_input, test_Y=w_test_target, gp_X=w_gp_input, gp_pred_mean=w_gp_pred_mean, gp_pred_std=w_gp_pred_std, inducing_points_X=w_my_model.variational_strategy.inducing_points_C.detach()) # NOTE: input is C not X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True v.s. Fitted latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_and_fitted_latent(w_X_true, w_my_model.X.q_mu.detach(), torch.nn.functional.softplus(w_my_model.X.q_log_sigma.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
